{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "import pytorch3d.ops\n",
    "from plyfile import PlyData, PlyElement\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from argparse import ArgumentParser, Namespace\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from arguments import ModelParams, PipelineParams, ModelHiddenParams\n",
    "from scene import Scene, GaussianModel, FeatureGaussianModel\n",
    "from gaussian_renderer import render, render_contrastive_feature, render_segmentation\n",
    "from segment_anything import (SamAutomaticMaskGenerator, SamPredictor,\n",
    "                              sam_model_registry)\n",
    "from utils.sh_utils import SH2RGB\n",
    "import imageio\n",
    "from utils.segment_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "FEATURE_DIM = 32\n",
    "\n",
    "DATA_ROOT = './data/hypernerf/split-cookie'\n",
    "# the model path, same to the --model_path in the training, after train_scene.py this folder will be created but named randomly\n",
    "MODEL_PATH = './output/hypernerf/split-cookie'\n",
    "# 'lego_real_night_radial'\n",
    "SPIN_SCENE_NAME = 'lego_real_night_radial'\n",
    "NVOS_SCENE_NAME = 'orchids'\n",
    "FEATURE_GAUSSIAN_ITERATION = 14000\n",
    "\n",
    "SAM_PROJ_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(FEATURE_GAUSSIAN_ITERATION)}/sam_proj.pt')\n",
    "NEG_PROJ_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(FEATURE_GAUSSIAN_ITERATION)}/neg_proj.pt')\n",
    "FEATURE_PCD_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(FEATURE_GAUSSIAN_ITERATION)}/contrastive_feature_point_cloud.ply')\n",
    "SCENE_PCD_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(FEATURE_GAUSSIAN_ITERATION)}/point_cloud.ply')\n",
    "\n",
    "SAM_ARCH = 'vit_h'\n",
    "SAM_CKPT_PATH = '/data/sxj/SegAnyGAussians/dependencies/sam_ckpt/sam_vit_h_4b8939.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear = torch.nn.Sequential(\n",
    "    torch.nn.Linear(256, 64, bias=True),\n",
    "    torch.nn.LayerNorm(64),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(64, 64, bias=True),\n",
    "    torch.nn.LayerNorm(64),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(64, FEATURE_DIM, bias=True),\n",
    ")\n",
    "nonlinear.load_state_dict(torch.load(SAM_PROJ_PATH))\n",
    "nonlinear = nonlinear.cuda()\n",
    "nonlinear.eval()\n",
    "\n",
    "parser = ArgumentParser(description=\"Testing script parameters\")\n",
    "model = ModelParams(parser, sentinel=True)\n",
    "# op = OptimizationParams(parser)\n",
    "pipeline = PipelineParams(parser)\n",
    "hp = ModelHiddenParams(parser)\n",
    "parser.add_argument(\"--iteration\", default=-1, type=int)\n",
    "parser.add_argument('--target', default='scene', const='scene', nargs='?', choices=['scene', 'seg', 'feature', 'coarse_seg_everything', 'contrastive_feature', 'xyz'])\n",
    "parser.add_argument('--idx', default=0, type=int)\n",
    "parser.add_argument(\"--configs\", type=str, default = \"./arguments/hypernerf/default.py\")\n",
    "parser.add_argument('--precomputed_mask', default=None, type=str)\n",
    "\n",
    "args = get_combined_args(parser, MODEL_PATH)\n",
    "\n",
    "if args.configs:\n",
    "    import mmcv\n",
    "    from utils.params_utils import merge_hparams\n",
    "    config = mmcv.Config.fromfile(args.configs)\n",
    "    args = merge_hparams(args, config)\n",
    "\n",
    "dataset = model.extract(args)\n",
    "hyperparam = hp.extract(args)\n",
    "dataset.need_features = True\n",
    "dataset.need_masks = True\n",
    "\n",
    "# gaussians = GaussianModel(dataset.sh_degree, hyperparam)\n",
    "gaussians = None\n",
    "feature_gaussians = FeatureGaussianModel(dataset.sh_degree, FEATURE_DIM, hyperparam)\n",
    "scene = Scene(dataset, gaussians, feature_gaussians, load_iteration=-1, feature_loaded_iteration=-1, target='contrastive_feature')\n",
    "\n",
    "xyz = feature_gaussians.get_xyz\n",
    "point_features = feature_gaussians.get_sam_features\n",
    "# print(xyz.device)\n",
    "# print(point_features.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = SAM_ARCH\n",
    "sam = sam_model_registry[model_type](checkpoint=SAM_CKPT_PATH).to('cuda')\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = [i for i in scene.getVideoCameras()]\n",
    "print(\"There are\",len(cameras),\"views in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_img_camera_id = 0\n",
    "mask_img_camera_id = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    view = cameras[ref_img_camera_id]\n",
    "    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]\n",
    "    background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "    rendering = render(view, feature_gaussians, pipeline, background, cam_type=\"blender\")[\"render\"]\n",
    "    print(rendering.shape)\n",
    "    img = to8b(rendering).transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    # plt.axis('off')\n",
    "    plt.show()\n",
    "    # img = cv2.resize(img.permute([1,2,0]).detach().cpu().numpy().astype(np.uint8), dsize=(1024,1024), fx=1, fy=1, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    predictor.set_image(img)\n",
    "    sam_feature = predictor.features\n",
    "    # sam_feature = view.original_features\n",
    "\n",
    "    bg_feature = [0 for i in range(FEATURE_DIM)]\n",
    "    background_feature = torch.tensor(bg_feature, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    rendered_feature = render_contrastive_feature(view, feature_gaussians, pipeline.extract(args), background_feature)['render']\n",
    "    time1 = time.time() - start_time\n",
    "    time1 = 0\n",
    "\n",
    "H, W = sam_feature.shape[-2:]\n",
    "print(\"sam_features: \", sam_feature.shape)\n",
    "# print(\"rendered_feature: \", rendered_feature.shape)\n",
    "\n",
    "# print(\"time1: \", time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_point = np.array([[300, 400]])\n",
    "input_label = np.ones(len(input_point))\n",
    "\n",
    "# plt.figure(figsize=(10,10))\n",
    "plt.imshow(img)\n",
    "show_points(input_point, input_label, plt.gca())\n",
    "plt.axis('on')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    vanilla_masks, scores, logits = predictor.predict(\n",
    "        point_coords=input_point,\n",
    "        point_labels=input_label,\n",
    "        multimask_output=True,\n",
    "    )\n",
    "    \n",
    "l = len(vanilla_masks)\n",
    "\n",
    "for i, (mask, score) in enumerate(zip(vanilla_masks, scores)):\n",
    "    plt.figure()\n",
    "    # plt.subplot(1, l, i+1)\n",
    "    plt.imshow(img)\n",
    "    show_mask(mask, plt.gca())\n",
    "    show_points(input_point, input_label, plt.gca())\n",
    "    plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vanilla_masks: \", vanilla_masks.shape)\n",
    "masks = torch.nn.functional.interpolate(torch.from_numpy(vanilla_masks).float().unsqueeze(0), (64,64), mode='bilinear').squeeze(0).cuda()\n",
    "masks[masks > 0.5] = 1\n",
    "masks[masks != 1] = 0\n",
    "print(\"masks resized: \", masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_id = 0\n",
    "mask_id = np.argmax(scores)\n",
    "origin_ref_mask = torch.tensor(vanilla_masks[mask_id]).float().cuda()\n",
    "\n",
    "# if origin_ref_mask.shape != (64,64):\n",
    "#     ref_mask = torch.nn.functional.interpolate(origin_ref_mask[None, None, :, :], (64,64), mode='bilinear').squeeze().cuda()\n",
    "#     ref_mask[ref_mask > 0.5] = 1\n",
    "#     ref_mask[ref_mask != 1] = 0\n",
    "# else:\n",
    "#     ref_mask = origin_ref_mask\n",
    "    \n",
    "# sam features\n",
    "\n",
    "low_dim_features = nonlinear(\n",
    "    sam_feature.view(-1, H*W).permute([1,0])\n",
    ").squeeze().permute([1,0]).reshape([-1, H, W])\n",
    "\n",
    "# Feature Field query\n",
    "# mask_low_dim_features = ref_mask.unsqueeze(0) * low_dim_features\n",
    "# mask_pooling_prototype = mask_low_dim_features.sum(dim = (1,2)) / torch.count_nonzero(ref_mask)\n",
    "ref_mask = torch.nn.functional.interpolate(origin_ref_mask[None, None, :, :], (358, 200), mode='bilinear').squeeze().cuda()\n",
    "ref_mask[ref_mask > 0.5] = 1\n",
    "ref_mask[ref_mask != 1] = 0\n",
    "mask_low_dim_features = ref_mask.unsqueeze(0) * rendered_feature\n",
    "mask_pooling_prototype = mask_low_dim_features.sum(dim = (1,2)) / torch.count_nonzero(ref_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmeans_pytorch\n",
    "import importlib\n",
    "importlib.reload(kmeans_pytorch)\n",
    "from kmeans_pytorch import kmeans\n",
    "\n",
    "# K-means or not\n",
    "\n",
    "bg_color = [0 for i in range(32)]\n",
    "background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "rendered_feature = render_contrastive_feature(view, feature_gaussians, pipeline.extract(args), background)['render']\n",
    "\n",
    "# similarity = torch.cosine_similarity(mask_pooling_prototype.cuda(), rendered_feature.permute([1, 2, 0]), dim=-1)\n",
    "\n",
    "temp_mask = torch.einsum('C,CHW->HW', mask_pooling_prototype.cuda(), rendered_feature)\n",
    "similarity = temp_mask.clone().detach()\n",
    "temp_mask = torch.nn.functional.interpolate(similarity.float().unsqueeze(0).unsqueeze(0), (64,64), mode='bilinear').squeeze().cuda()\n",
    "temp_mask[temp_mask > 0] = 1\n",
    "temp_mask[temp_mask != 1] = 0\n",
    "\n",
    "\n",
    "ref_mask = torch.nn.functional.interpolate(origin_ref_mask[None, None, :, :], (64, 64), mode='bilinear').squeeze().cuda()\n",
    "ref_mask[ref_mask > 0.5] = 1\n",
    "ref_mask[ref_mask != 1] = 0\n",
    "iob = (temp_mask * ref_mask).sum(dim = (-1, -2)) / ref_mask.sum()\n",
    "print(iob.item())\n",
    "\n",
    "if iob > 0.9:\n",
    "    fmask_prototype = mask_pooling_prototype.unsqueeze(0)\n",
    "# else:\n",
    "#     # fmask_prototype = mask_pooling_prototype.unsqueeze(0)\n",
    "#     downsampled_masks = torch.nn.functional.adaptive_avg_pool2d(ref_mask.unsqueeze(0).unsqueeze(0), (8,8)).squeeze()\n",
    "#     downsampled_features = torch.nn.functional.adaptive_avg_pool2d(mask_low_dim_features.unsqueeze(0), (8,8)).squeeze(0)\n",
    "#     downsampled_features /= downsampled_masks.unsqueeze(0)\n",
    "\n",
    "#     downsampled_masks[downsampled_masks != 0]= 1\n",
    "#     init_prototypes = downsampled_features[:, downsampled_masks.bool()].permute([1,0])\n",
    "\n",
    "\n",
    "#     masked_sam_features = low_dim_features[:, ref_mask.bool()]\n",
    "#     masked_sam_features = masked_sam_features.permute([1,0])\n",
    "    \n",
    "#     num_clusters = init_prototypes.shape[0]\n",
    "#     print(num_clusters)\n",
    "    \n",
    "#     if num_clusters <= 1:\n",
    "#         num_clusters = min(int(masked_sam_features.shape[0] ** 0.5), 32)\n",
    "#         init_prototypes = []\n",
    "\n",
    "#     cluster_ids_x, cluster_centers = kmeans(\n",
    "#         X=masked_sam_features, num_clusters=num_clusters, distance='euclidean', device=torch.device('cuda')\n",
    "#     )\n",
    "\n",
    "    # temp_mask = torch.sigmoid(torch.einsum('NC,CHW->NHW', cluster_centers.cuda(), rendered_feature))\n",
    "    # temp_mask = torch.nn.functional.interpolate(temp_mask.float().unsqueeze(1), (64,64), mode='bilinear').squeeze().cuda()\n",
    "    # temp_mask[temp_mask >= 0.5] = 1\n",
    "    # temp_mask[temp_mask != 1] = 0\n",
    "    # temp_mask = temp_mask.squeeze()\n",
    "\n",
    "    # ioa = (temp_mask * ref_mask[None,:,:]).sum(dim = (-1, -2)) / (temp_mask.sum(dim = (-1, -2)) + 1e-5)\n",
    "    # iob = (temp_mask * ref_mask[None,:,:]).sum(dim = (-1, -2)) / ref_mask.sum()\n",
    "    # ioa = ioa.squeeze()\n",
    "    # iob = iob.squeeze()\n",
    "    # cluster_mask = ioa > 0.75\n",
    "\n",
    "    # # NMS\n",
    "    # for i in range(len(cluster_mask)):\n",
    "    #     if not cluster_mask[i]:\n",
    "    #         continue\n",
    "\n",
    "    #     for j in range(i+1, len(cluster_mask)):\n",
    "    #         if not cluster_mask[j]:\n",
    "    #             continue\n",
    "\n",
    "    #         if (temp_mask[j] * temp_mask[i]).sum() / ((temp_mask[j] + temp_mask[i]).sum() - (temp_mask[j] * temp_mask[i]).sum()) > 0.75:\n",
    "    #             if ioa[i] > ioa[j]:\n",
    "    #                 cluster_mask[j] = False\n",
    "    #             else:\n",
    "    #                 cluster_mask[i] = False\n",
    "    #                 break\n",
    "    \n",
    "    # cluster_centers = cluster_centers.cuda()\n",
    "    # cluster_centers = cluster_centers[cluster_mask, :]\n",
    "#     fmask_prototype = torch.cat([mask_pooling_prototype.unsqueeze(0), cluster_centers.cuda()], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity = torch.einsum('NC, CHW -> NHW', fmask_prototype, rendered_feature)\n",
    "# similarity = similarity.max(0)[0]\n",
    "\n",
    "# normalized_similarity_mask = (similarity_mask - similarity_mask.min()) / (similarity_mask.max() - similarity_mask.min())\n",
    "# feature_map = torch.sigmoid(similarity).detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(similarity.detach().cpu().numpy())\n",
    "# plt.imshow(feature_map)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
