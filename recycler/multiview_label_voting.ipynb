{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from argparse import ArgumentParser\n",
    "from tqdm import tqdm\n",
    "from arguments import ModelParams, PipelineParams, ModelHiddenParams\n",
    "from scene import Scene, GaussianModel\n",
    "from gaussian_renderer import render, render_contrastive_feature, render_segmentation, render_mask\n",
    "import imageio\n",
    "from utils.segment_utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIM = 32\n",
    "\n",
    "DATA_ROOT = './data/dynerf/cut_roasted_beef'\n",
    "# the model path, same to the --model_path in the training, after train_scene.py this folder will be created but named randomly\n",
    "MODEL_PATH = './output/dynerf/cut_roasted_beef'\n",
    "GAUSSIAN_ITERATION = 14000\n",
    "\n",
    "SAM_PROJ_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(GAUSSIAN_ITERATION)}/sam_proj.pt')\n",
    "NEG_PROJ_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(GAUSSIAN_ITERATION)}/neg_proj.pt')\n",
    "FEATURE_PCD_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(GAUSSIAN_ITERATION)}/feature_point_cloud.ply')\n",
    "SCENE_PCD_PATH = os.path.join(MODEL_PATH, f'point_cloud/iteration_{str(GAUSSIAN_ITERATION)}/scene_point_cloud.ply')\n",
    "\n",
    "# SAM_ARCH = 'vit_h'\n",
    "# SAM_CKPT_PATH = '/data/sxj/dependencies/sam_ckpt/sam_vit_h_4b8939.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for config file in ./output/dynerf/cut_roasted_beef/cfg_args\n",
      "Config file found at: ./output/dynerf/cut_roasted_beef/cfg_args\n",
      "mode:  scene\n",
      "Loading trained model at iteration 14000\n",
      "meta data loaded, total image:5700\n",
      "meta data loaded, total image:300\n",
      "load finished. Train Dataset Length: 5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5700/5700 [00:00<00:00, 184829.67it/s]\n",
      "300it [00:00, 39452.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin points, 37243\n",
      "after points, 37243\n",
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Loading Video Cameras\n",
      "Deformation Net Set aabb [21.35526085 15.11961842 50.36367798] [-25.87877274 -14.45879078   5.38203239]\n",
      "Voxel Plane: set aabb= Parameter containing:\n",
      "tensor([[ 21.3553,  15.1196,  50.3637],\n",
      "        [-25.8788, -14.4588,   5.3820]])\n",
      "loading model from exists./output/dynerf/cut_roasted_beef/point_cloud/iteration_14000\n"
     ]
    }
   ],
   "source": [
    "parser = ArgumentParser(description=\"Render script parameters\")\n",
    "model = ModelParams(parser, sentinel=True)\n",
    "# op = OptimizationParams(parser)\n",
    "pipeline = PipelineParams(parser)\n",
    "hp = ModelHiddenParams(parser)\n",
    "parser.add_argument(\"--iteration\", default=-1, type=int)\n",
    "parser.add_argument('--mode', default='scene', choices=['scene', 'feature'])\n",
    "parser.add_argument(\"--configs\", type=str, default = \"./arguments/dynerf/cut_roasted_beef.py\")\n",
    "# parser.add_argument('--precomputed_mask', default=None, type=str)\n",
    "args = get_combined_args(parser, MODEL_PATH, 'scene')\n",
    "if args.configs:\n",
    "    import mmcv\n",
    "    from utils.params_utils import merge_hparams\n",
    "    config = mmcv.Config.fromfile(args.configs)\n",
    "    args = merge_hparams(args, config)\n",
    "\n",
    "dataset = model.extract(args)\n",
    "hyperparam = hp.extract(args)\n",
    "dataset.object_masks = True\n",
    "dataset.need_gt_masks = True\n",
    "\n",
    "gaussians = GaussianModel(dataset.sh_degree, args.mode, hyperparam)\n",
    "scene = Scene(dataset, gaussians, load_iteration=args.iteration, mode=args.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5700 views in the dataset.\n"
     ]
    }
   ],
   "source": [
    "bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]\n",
    "bg_color = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "video_cameras = scene.getVideoCameras()\n",
    "train_cams = scene.getTrainCameras()\n",
    "cam_type = scene.dataset_type\n",
    "print(\"There are\",len(train_cams),\"views in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    view = train_cams[5399]\n",
    "    \n",
    "    gt_mask = (view.objects != 0).int().cuda()\n",
    "    gt_mask = torch.any(gt_mask, dim=-1).int()\n",
    "    \n",
    "    render_pkg = render(view, gaussians, pipeline, bg_color, cam_type=scene.dataset_type)\n",
    "    points2d = render_pkg[\"points2d\"].round().long()\n",
    "    mask3d = (points2d[:, 1] >= 0) & (points2d[:, 1] < view.image_height) & (points2d[:, 0] >= 0) & (points2d[:, 0] < view.image_width)\n",
    "    mask = mask3d\n",
    "    visible_points2d = points2d[mask3d]\n",
    "    points2d_values = gt_mask[visible_points2d[:, 1], visible_points2d[:, 0]]\n",
    "    \n",
    "    mask3d[mask3d.clone()] = (points2d_values == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering progress:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering progress: 100%|██████████| 300/300 [00:09<00:00, 32.34it/s]\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1352, 1014) to (1360, 1024) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 32.344379595861824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x6c79f80] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    }
   ],
   "source": [
    "render_images = []\n",
    "with torch.no_grad():\n",
    "    for idx, view in enumerate(tqdm(video_cameras, desc=\"Rendering progress\")):\n",
    "        if idx == 0: time1 = time.time()\n",
    "        \n",
    "        # # nearest interpolate\n",
    "        # diff = torch.abs(gaussians._time_map - view.time)\n",
    "        # index = torch.argmin(diff)\n",
    "        # mask = gaussians._mask_table[index]\n",
    "            \n",
    "        rendering = render_segmentation(view, gaussians, pipeline, bg_color, ~mask3d.bool())[\"render\"]\n",
    "        render_images.append(to8b(rendering.detach()).transpose(1,2,0))\n",
    "\n",
    "time2 = time.time()\n",
    "print(\"FPS:\", len(video_cameras) / (time2 - time1))\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "imageio.mimwrite(os.path.join(MODEL_PATH, 'video', \"ours_{}\".format(GAUSSIAN_ITERATION), 'video_seg_man.mp4'), render_images, fps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians.create_mask_table(len(train_cams))\n",
    "# viewpoint_stack = [i for i in train_cams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5700/5700 [08:46<00:00, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 526.0199625492096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    time1 = time.time()\n",
    "    for idx, view in enumerate(tqdm(train_cams)):\n",
    "        # gaussians._time_map[idx] = view.time\n",
    "        diff = torch.abs(gaussians._time_map - view.time)\n",
    "        index = torch.argmin(diff)\n",
    "        # if index != 0: continue\n",
    "        gt_mask = (view.objects != 0).int().cuda()\n",
    "        gt_mask = torch.any(gt_mask, dim=-1).int()\n",
    "        \n",
    "        render_pkg = render(view, gaussians, pipeline, bg_color, cam_type=scene.dataset_type)\n",
    "        points2d = render_pkg[\"points2d\"].round().long()\n",
    "        mask3d = (points2d[:, 1] >= 0) & (points2d[:, 1] < view.image_height) & (points2d[:, 0] >= 0) & (points2d[:, 0] < view.image_width)\n",
    "        visible_points2d = points2d[mask3d]\n",
    "        points2d_values = gt_mask[visible_points2d[:, 1], visible_points2d[:, 0]]\n",
    "        \n",
    "        gaussians._mask_table[index][mask3d] += (points2d_values == 1).float()\n",
    "    \n",
    "    mask_table = gaussians._mask_table\n",
    "    # gaussians._mask_table /= 19\n",
    "    # gaussians._mask_table = gaussians._mask_table >= 0.5\n",
    "    \n",
    "    time2 = time.time()\n",
    "    print(\"time:\", time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussians._mask_table = mask_table / 19\n",
    "gaussians._mask_table = (gaussians._mask_table >= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19., device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_table.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering progress:   0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering progress: 100%|██████████| 300/300 [00:06<00:00, 45.24it/s]\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (1352, 1014) to (1360, 1024) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 45.26533123352721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[swscaler @ 0x6a6bb40] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    }
   ],
   "source": [
    "render_images = []\n",
    "with torch.no_grad():\n",
    "    for idx, view in enumerate(tqdm(video_cameras, desc=\"Rendering progress\")):\n",
    "        if idx == 0: time1 = time.time()\n",
    "        \n",
    "        # nearest interpolate\n",
    "        diff = torch.abs(gaussians._time_map - view.time)\n",
    "        index = torch.argmin(diff)\n",
    "        mask = gaussians._mask_table[index]\n",
    "            \n",
    "        rendering = render_segmentation(view, gaussians, pipeline, bg_color, mask.bool())[\"render\"]\n",
    "        render_images.append(to8b(rendering.detach()).transpose(1,2,0))\n",
    "\n",
    "time2 = time.time()\n",
    "print(\"FPS:\", len(video_cameras) / (time2 - time1))\n",
    "torch.cuda.empty_cache()\n",
    "    \n",
    "imageio.mimwrite(os.path.join(MODEL_PATH, 'video', \"ours_{}\".format(GAUSSIAN_ITERATION), 'video_seg_man.mp4'), render_images, fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gaussians4D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
